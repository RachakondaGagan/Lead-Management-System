// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// services/chatService.js ‚Äî Agentic Intake Service (Rewrite)
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
//
// ARCHITECTURE: True Tool-Calling Agent
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
// Instead of rigid JSON parsing, this service uses LangChain's
// `createToolCallingAgent` + `AgentExecutor`. The Gemini model
// has a fluid, intelligent conversation AND can autonomously
// decide when to call the `trigger_deep_research` tool.
//
// Memory: Per-user `ChatMessageHistory` stored in an in-memory
// Map (keyed by userId). Each user gets an independent agent
// loop with its own conversation history.
//
// NOTE: Agent + Executor are lazy-initialized on first request
// to avoid top-level await that could silently hang at import.
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { createToolCallingAgent, AgentExecutor } from "langchain/agents";
import {
    ChatPromptTemplate,
    MessagesPlaceholder,
} from "@langchain/core/prompts";
import { ChatMessageHistory } from "langchain/stores/message/in_memory";
import Session from "../models/Session.js";
import triggerDeepResearch from "../tools/triggerDeepResearch.js";
import { executeDeepResearch } from "./researchService.js";

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// 1. IN-MEMORY STORE ‚Äî userId ‚Üí ChatMessageHistory
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

const memoryStore = new Map();

function getOrCreateHistory(userId) {
    if (!memoryStore.has(userId)) {
        const history = new ChatMessageHistory();
        history.addAIMessage("I'm your Elite AI Growth Consultant. Tell me about your business (Niche, Audience, and Value Proposition), and I will actively orchestrate a deep research pipeline for explosive lead generation.");
        memoryStore.set(userId, history);
    }
    return memoryStore.get(userId);
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// 2. SYSTEM PROMPT ‚Äî Elite B2B Growth Consultant
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

const SYSTEM_PROMPT = `You are an elite, aggressive B2B Growth Consultant and Data Scientist working for a premier AI-powered lead-generation platform.

## YOUR MISSION
Extract the absolute core of the user's business model (Niche, Audience, Value Prop) as fast as humanly possible, ideally in a single turn, so you can unleash the Deep Research swarm. 

## YOUR PERSONALITY
- You are sharp, highly strategic, and demanding but polite.
- You do NOT make small talk. Every word serves to extract business intelligence.
- Ask penetrating, highly-focused questions.

## WHAT YOU MUST EXTRACT
1. **Business Niche / Product** ‚Äî What do they actually sell?
2. **Target Audience** ‚Äî Who are their ideal buyers? (job titles, company size, vertical)
3. **Core Value Proposition** ‚Äî What specific pain point do they solve?

## RULES
- If the user provides a comprehensive overarching answer, IMMEDIATELY call the \`trigger_deep_research\` tool. Do not ask follow ups if you have enough to search.
- If you lack clarity, ask ONE extremely pointed question. Never ask a list of questions.
- NEVER break character.
- The user is busy. Save their time.

## WHEN TO DEPLOY RESEARCH
The millisecond you have sufficient data for Niche, Audience, and Value Prop ‚Äî call the \`trigger_deep_research\` tool. 
Do not warn the user in a separate message. Call the tool and summarize what you are doing.`;

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// 3. TOOLS & PROMPT (static config ‚Äî no async needed)
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

const tools = [triggerDeepResearch];

const agentPrompt = ChatPromptTemplate.fromMessages([
    ["system", SYSTEM_PROMPT],
    new MessagesPlaceholder("chat_history"),
    ["human", "{input}"],
    new MessagesPlaceholder("agent_scratchpad"),
]);

const model = new ChatGoogleGenerativeAI({
    model: "gemini-2.5-flash",
    temperature: 0.6,
    maxOutputTokens: 2048,
});

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// 4. LAZY SINGLETON ‚Äî Agent + Executor
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// We avoid top-level `await` which can silently hang the module.
// Instead, we initialise on the first request and cache.
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

let _agentExecutor = null;

async function getAgentExecutor() {
    if (_agentExecutor) return _agentExecutor;

    console.log("ü§ñ Lazy-initializing intake agent + executor...");
    const agent = await createToolCallingAgent({
        llm: model,
        tools,
        prompt: agentPrompt,
    });

    _agentExecutor = new AgentExecutor({
        agent,
        tools,
        verbose: process.env.NODE_ENV === "development",
        maxIterations: 5,
        returnIntermediateSteps: true,
    });

    console.log("‚úÖ Intake agent ready.");
    return _agentExecutor;
}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// 5. PUBLIC API
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

/**
 * Process a user message through the intake agent.
 *
 * @param {string} userId     ‚Äì Unique identifier for the user
 * @param {string} userMessage ‚Äì The user's latest message
 * @returns {{
 *   reply: string,
 *   toolTriggered: boolean,
 *   toolData: object | null
 * }}
 */
export async function processIntakeMessage(userId, userMessage) {
    // ‚îÄ‚îÄ Lazy-init the agent executor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    const agentExecutor = await getAgentExecutor();

    // ‚îÄ‚îÄ Retrieve (or create) this user's conversation history ‚îÄ‚îÄ
    const chatHistory = getOrCreateHistory(userId);

    // ‚îÄ‚îÄ Get all past messages as an array for the agent ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    const previousMessages = await chatHistory.getMessages();

    // ‚îÄ‚îÄ Invoke the agent executor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    const result = await agentExecutor.invoke({
        input: userMessage,
        chat_history: previousMessages,
    });

    // ‚îÄ‚îÄ Extract the final text reply ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    let reply = result.output;
    let toolTriggered = false;
    let toolData = null;

    // ‚îÄ‚îÄ 1. Check intermediateSteps first (ideal path) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    const intermediateSteps = result.intermediateSteps || [];
    const researchStep = intermediateSteps.find(
        (step) => step.action.tool === "trigger_deep_research"
    );

    if (researchStep) {
        toolTriggered = true;
        toolData = researchStep.action.toolInput;
    }

    // ‚îÄ‚îÄ 2. Fallback: Check if output itself contains a functionCall ‚îÄ‚îÄ
    // Gemini 2.5 sometimes returns the tool call in the raw output
    // instead of intermediateSteps (especially with thinking mode).
    if (!toolTriggered && typeof reply !== "string") {
        if (Array.isArray(reply)) {
            const funcCallEntry = reply.find(
                (entry) => entry?.functionCall?.name === "trigger_deep_research"
            );
            if (funcCallEntry) {
                toolTriggered = true;
                toolData = funcCallEntry.functionCall.args || {};
                console.log("üîç Detected trigger_deep_research in raw output (fallback path).");
            }
        }
    }

    // ‚îÄ‚îÄ 3. Sanitize reply to a string ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if (typeof reply !== "string") {
        if (Array.isArray(reply) && reply[0]?.text) {
            reply = reply[0].text;
        } else if (toolTriggered) {
            reply = "I have enough information to proceed. Deploying research agents now...";
        } else {
            reply = "I'm processing your request. One moment please...";
        }
    }

    // ‚îÄ‚îÄ 4. If tool triggered but toolData is empty, reconstruct ‚îÄ‚îÄ
    // Gemini sometimes calls the tool with empty args. We reconstruct
    // the business summary from the full conversation history.
    if (toolTriggered && (!toolData?.comprehensive_business_summary)) {
        console.log("‚ö†Ô∏è Tool args were empty. Reconstructing from conversation history.");

        // Build a transcript of all human messages as the summary
        const allMessages = await chatHistory.getMessages();
        const humanMessages = [];
        for (const msg of allMessages) {
            // LangChain message objects have a `content` property and `_getType()` method
            const msgType = msg._getType?.() || msg.constructor?.name || "";
            if (msgType === "human" || msg.role === "human") {
                humanMessages.push(msg.content);
            }
        }
        // Include the current message too
        humanMessages.push(userMessage);

        toolData = {
            comprehensive_business_summary: humanMessages.join("\n\n"),
            suggested_search_angles: "Analyze competitors, identify market gaps, generate scraper parameters for LinkedIn/Apollo.io, and craft targeted ad creative concepts."
        };
    }

    // ‚îÄ‚îÄ Update the in-memory history ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    await chatHistory.addUserMessage(userMessage);
    await chatHistory.addAIMessage(reply);

    // ‚îÄ‚îÄ Persist to MongoDB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    const updatePayload = {
        $push: {
            conversationHistory: {
                $each: [
                    { role: "human", content: userMessage },
                    { role: "ai", content: reply },
                ],
            },
        },
    };

    if (toolTriggered) {
        updatePayload.$set = {
            status: "intake_complete",
            toolCallData: toolData,
        };

        console.log(`\nüöÄ Tool triggered! Firing background executeDeepResearch for user: ${userId}`);
        executeDeepResearch(
            toolData.comprehensive_business_summary,
            toolData.suggested_search_angles,
            userId
        ).catch(error => {
            console.error(`‚ùå Background deep research failed for user ${userId}:`, error);
        });
    }

    await Session.findOneAndUpdate({ userId }, updatePayload, {
        upsert: true,
        new: true,
    });

    return { reply, toolTriggered, toolData };
}

/**
 * Retrieve conversation history for a user from MongoDB.
 */
export async function getUserHistory(userId) {
    const session = await Session.findOne({ userId });
    return session ? session.conversationHistory : [];
}
